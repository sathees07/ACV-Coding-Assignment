# Applied CV Coding Assignment

This repository contains the code, pipelines, and documentation for an end-to-end object detection project using the BDD100K dataset. The project encompasses:

- Dataset analysis
- Model training
- Model evaluation
- Containerized deployment for data tasks

Below is a breakdown of the repository structure and instructions for running and utilizing each task.

---

## ðŸ“‚ Folder Structure

```
.
â”œâ”€â”€ 01_data_analysis
â”‚Â Â  â”œâ”€â”€ app.py
â”‚Â Â  â”œâ”€â”€ config.json
â”‚Â Â  â”œâ”€â”€ data-analysis.ipynb
â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”œâ”€â”€ extract_od_data.py
â”‚Â Â  â”œâ”€â”€ README.md
â”‚Â Â  â””â”€â”€ requirements.txt
â”œâ”€â”€ 02_model_training
â”‚Â Â  â”œâ”€â”€ bdd_to_yolo.py
â”‚Â Â  â”œâ”€â”€ dataset
â”‚Â Â  â”œâ”€â”€ dataset.yml
â”‚Â Â  â”œâ”€â”€ runs
â”‚Â Â  â”œâ”€â”€ training.ipynb
â”‚Â Â  â”œâ”€â”€ training_steps.png
â”‚Â Â  â””â”€â”€ yolov8n.pt
â”œâ”€â”€ 03_evaluation_visualization
â”‚Â Â  â”œâ”€â”€ failure_analysis.py
â”‚Â Â  â”œâ”€â”€ qual_performance_eval.py
â”‚Â Â  â””â”€â”€ quan_performance_eval.ipynb
â””â”€â”€ README.md
```

# Data Analysis

The Data Analysis folder contains scripts to analyze and visualize the dataset using a Streamlit-based UI. The task involves filtering data, viewing labels, and performing exploratory data analysis (EDA).

Initial Setup
-------------

### 1\. Clone the GitHub Repository

To begin, clone the repository containing the analysis code:

git clone <https://github.com/sathees07/ACV-Coding-Assignment.git>

cd ACV-Coding-Assignment

### 2\. Download the Dataset

Download the BDD100K dataset from the provided link:

-   [Download Link](https://drive.google.com/file/d/1NgWX5YfEKbloAKX9l8kUVJFpWFlUO8UT/view?usp=sharing)

Place the downloaded files in the main folder.

### 3\. Data Preprocessing

The dataset contains annotations for object detection, drivable area, and lane markings in a JSON format. For this task, only object detection labels were extracted.

# Extraction Steps

1.  Navigate to the directory `01_data_analysis`

`cd 01_data_analysis`

1.  Use the provided parsing script to extract object detection data:\
    `python extract_od_data.py --input <path-to-json> --output <output-path>`

For example,

To extract from train dataset:\
`python3 extract_od_data.py --input ../assignment_data_bdd/bdd100k_labels_release/bdd100k/labels/bdd100k_labels_images_train.json --output od_train.json`

To extract from val dataset:\
`python3 extract_od_data.py --input ../assignment_data_bdd/bdd100k_labels_release/bdd100k/labels/bdd100k_labels_images_val.json --output od_val.json`

The script filters the JSON file to retain only the object detection annotations (e.g., car, person, traffic light, etc.) and stores the output in a simplified JSON format.


The folder structure is as follows:

```
.
â”œâ”€â”€ app.pyÂ  Â  Â  Â  Â  Â  Â  Â  Â  # Dashboard app for visualization
â”œâ”€â”€ config.jsonÂ  Â  Â  Â  Â  Â  Â # Configuration file for app.py
â”œâ”€â”€ data-analysis.ipynbÂ  Â  Â # Jupyter notebook used for developing app.py
â”œâ”€â”€ DockerfileÂ  Â  Â  Â  Â  Â  Â  # Docker container file
â”œâ”€â”€ extract_od_data.pyÂ  Â  Â  # Script for extracting object detection data
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txtÂ  Â  Â  Â  # List of required packages
â”œâ”€â”€ train.jsonÂ  Â  Â  Â  Â  Â    # Output file from data preprocessing (Train)
â””â”€â”€ val.jsonÂ  Â  Â  Â  Â  Â  Â    # Output file from data preprocessing (Val)

```

### Configuration File (config.json)

The config.json file provides the necessary configuration for running app.py. Its contents are as follows:

```
{

Â Â "input_json": "od_val.json",

Â Â "image_path": "assignment_data_bdd/bdd100k_images_100k/bdd100k/images/100k/val/"

}
```

#### Modifying the Configuration

-   To analyze the validation dataset, keep the default values:
```
input_json: od_val.json
image_path: assignment_data_bdd/bdd100k_images_100k/bdd100k/images/100k/val/

```

-   To analyze the training dataset, update the configuration as follows:

```
input_json: od_train.json
Image_path: assignment_data_bdd/bdd100k_images_100k/bdd100k/images/100k/train/
```

The analysis environment is fully containerized using Docker. The Dockerfile is located in this folder. To build and run the container:

```
docker build -t data-analysis-app .

docker run -p 8501:8501 -v $(pwd)/config.json:/app/config.json -v /<dataset_path>/assignment_data_bdd/:/app/assignment_data_bdd/ data-analysis-app .

```

- After running the command, Streamlit will automatically open the app in your default web browser.

- If the browser doesn't open automatically, check the terminal for the URL provided by Streamlit.

- Manually copy and paste the URL into your browser. Typically, this will be:

```
Local URL: http://localhost:8501
Network URL: http://0.0.0.0:8501
```

### Workflow

**1.  Select a Section:**

-   Use the sidebar to navigate to a specific analysis section.

**2.  Interact with Visualizations:**

-   View charts or interact with the dataset insights.

**3.  Explore Images:**

-   Use the Image Viewer to browse through images with annotations.

-   Use the Category-Based Viewer for focused analysis on a specific object category.


All the steps involved in the BDD100K dataset analysis app are documented in the ```01_data_analysis/README.md``` file. Please refer to that file for a comprehensive guide on how to:

-   Navigate through the UI.

-   Filter and analyze the BDD100K dataset.

-   Access specific functionalities like category filtering and label-based image exploration.
